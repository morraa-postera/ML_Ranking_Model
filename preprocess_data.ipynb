{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the main preprocessing file that takes activity data by chemical class and creates the necessary features and target data for the model. We create the input features (differences of molecule fingerprints) and the target data (binary outcome of 'more' or 'less' active). We move here from an absolute potency space to a relative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity, BulkTanimotoSimilarity\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import pickle\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import random\n",
    "\n",
    "\n",
    "def Morgan_Fingerprint(smile, nbits = 512):\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smile),3,nBits=nbits, useFeatures = True)\n",
    "\n",
    "def Atom_Pair(smile):\n",
    "    return rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(Chem.MolFromSmiles(smile),nBits = 512)\n",
    "\n",
    "def TopologicalTorsion(smile):\n",
    "    return rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(Chem.MolFromSmiles(smile),nBits = 512)\n",
    "\n",
    "def concat_fingerprints(smile): # our default feature set throughout this model is a concatenation of 3 fingerprint sets\n",
    "    MF = Morgan_Fingerprint(smile)\n",
    "    AP = Atom_Pair(smile)\n",
    "    TT = TopologicalTorsion(smile)\n",
    "    return np.array(MF + AP + TT)\n",
    "\n",
    "def get_similarity(ref, comps):\n",
    "    return BulkTanimotoSimilarity(ref, comps)\n",
    "\n",
    "def IC50_diff(compound_a, compound_b):\n",
    "    if (compound_a == np.inf) | (compound_b == np.inf):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return compound_a - compound_b\n",
    "\n",
    "def duplicate_meta_data(meta_data): # needed when doing the 'Train-Test' split to account for the 'reverses'\n",
    "    \n",
    "    original_meta = pd.DataFrame(meta_data)\n",
    "    duplicate_meta = pd.DataFrame(columns = original_meta.columns)\n",
    "    duplicate_meta['Data_Split'], duplicate_meta['Test_Style'] = original_meta['Data_Split'], original_meta['Test_Style']\n",
    "    duplicate_meta['Compound_A'], duplicate_meta['Compound_B'] = original_meta['Compound_B'], original_meta['Compound_A']\n",
    "    duplicate_meta['Compound_A_IC50'], duplicate_meta['Compound_B_IC50'] = original_meta['Compound_B_IC50'], original_meta['Compound_A_IC50']\n",
    "    duplicate_meta['IC50_diff'] = -original_meta['IC50_diff']\n",
    "    \n",
    "    assert original_meta.shape == duplicate_meta.shape, \"Shapes not matching\"\n",
    "    \n",
    "    return original_meta.append(duplicate_meta, ignore_index = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function deserves its own commentary. \n",
    "\n",
    "1. It's the main function that turns absolute data into relative data. We generate fingerprint differences only if there is a sufficient difference between the IC50 data and avoid differences with one's self.\n",
    "\n",
    "\n",
    "2. Moreover, the data splits are very important -- if we want a totally distinct train and test set (no molecule is implicity seen in both; this is more 'challenging' for the model and we use it as default) then there is no need to add the 'reverse' differences. However if we want a partial overlap in train/test (as this is closer to reality at inference) we do need to add the reverse differences -- the type of split can be specificed as a parameter 'test_split'.\n",
    "\n",
    "\n",
    "3. It's easier to just carry around the vector of fingerprint diffs than all the ancillary data such as original SMILES, IC50 etc so we also create meta_data CSV of these details that can be picked up and included in analysis (most likely after we've trained the model and want to do some inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_difference_data(train_df, test_df, type_split, test_split = 'Test-Test'): \n",
    "    \n",
    "    # type_split is either 'Train' or 'Test' while test_split is either 'Test-Test' or 'Train-Test'\n",
    "       \n",
    "    if type_split == 'Train': # training set internal diffs\n",
    "        df = train_df\n",
    "        ref_df = train_df\n",
    "    else: # cross diffs or test set internal diffs\n",
    "        df = test_df\n",
    "        if test_split == 'Test-Test':\n",
    "            ref_df = test_df # train_df\n",
    "        else:\n",
    "            ref_df = train_df\n",
    "        \n",
    "    fp_diffs = []\n",
    "    activity_diffs = []\n",
    "    meta_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        for index, ref_row in ref_df.iterrows():\n",
    "            if (np.array_equal(row['fingerprint'], ref_row['fingerprint']) == False) & (abs(row['IC50'] - ref_row['IC50']) > 5):\n",
    "                fp_diffs.append(np.array(row['fingerprint']) - np.array(ref_row['fingerprint']))\n",
    "                meta_data.append({ 'Data_Split' : type_split, 'Test_Style' : test_split,\n",
    "                                  'Compound_A' : row['SMILES'], 'Compound_B' : ref_row['SMILES'],\n",
    "                                  'Compound_A_IC50' : row['IC50'], 'Compound_B_IC50' : ref_row['IC50'],\n",
    "                                  'IC50_diff' : IC50_diff(row['IC50'], ref_row['IC50'])})\n",
    "                if row['IC50'] < ref_row['IC50']:\n",
    "                    activity_diffs.append(1)\n",
    "                else:\n",
    "                    activity_diffs.append(-1)\n",
    "    \n",
    "    fp_diffs = np.vstack(fp_diffs)\n",
    "    \n",
    "    if test_split == 'Train-Test':\n",
    "        return np.concatenate((fp_diffs,-fp_diffs)), np.concatenate((np.array(activity_diffs),-np.array(activity_diffs))), duplicate_meta_data(meta_data)\n",
    "    else:\n",
    "        return fp_diffs, activity_diffs, pd.DataFrame(meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow for the preprocessing of several datasets if we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "             'noncovalent' : pd.read_csv('known_noncovalent_activity.csv')\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function should be quite self explanatory except for the 'split' line. \n",
    "\n",
    "- Basically this is used to split the ABSOLUTE data into a train and test set which is then converted into a RELATIVE train and test set. \n",
    "- The quirk is that we double the training data of acrylamides using noncovalent samples. My aim is to always produce a RELATIVE train/test split of 80:20 and (a bit of maths later) this implies the split shown below are needed when splitting the ABSOLUTE data -- these are only aproximations as they don't account for when IC50s are not significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, df in datasets.items():\n",
    "       \n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool: \n",
    "        df['fingerprint'] = pool.map(concat_fingerprints, df['SMILES'], 1) # get fingerprints\n",
    "    \n",
    "    if label == 'acrylamide':\n",
    "        split = np.sqrt(2)/(1 + np.sqrt(2))\n",
    "    else: \n",
    "        split = 2/3\n",
    "    \n",
    "    msk = np.random.rand(len(df)) < split\n",
    "    train_df = df[msk]\n",
    "    test_df = df[~msk]\n",
    "    \n",
    "    print( label, ' Train active/inactive split:', train_df.groupby(by = 'activity').count(), '\\n')\n",
    "    print( label, ' Test active/inactive split:', test_df.groupby(by = 'activity').count(), '\\n')\n",
    "    \n",
    "    X_train, y_train, meta_train = generate_difference_data(train_df, test_df, 'Train', '_')\n",
    "    X_valid, y_valid, meta_valid = generate_difference_data(train_df, test_df, 'Valid', 'Test-Test')\n",
    "    meta_data = meta_train.append(meta_valid, ignore_index = True).reset_index(drop = True)\n",
    "    \n",
    "    print(label + ' shape:', X_train.shape, X_valid.shape, '\\n')\n",
    "    \n",
    "    meta_data.to_csv('meta_data.csv', index = False)\n",
    "\n",
    "    with open(label + '_model_data', 'wb') as filename:\n",
    "        pickle.dump([X_train, y_train, X_valid, y_valid], filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additonal function to combine datasets together if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('acrylamide_model_data', 'rb') as filehandle:\n",
    "#     data_1 = pickle.load(filehandle)\n",
    "\n",
    "# with open('noncovalent_model_data', 'rb') as filehandle:\n",
    "#     data_2 = pickle.load(filehandle)\n",
    "\n",
    "# X_train_1, y_train_1, X_valid_1, y_valid_1 = np.array(data_1[0]), np.array(data_1[1]), np.array(data_1[2]), np.array(data_1[3])\n",
    "# X_train_2, y_train_2, X_valid_2, y_valid_2 = np.array(data_2[0]), np.array(data_2[1]), np.array(data_2[2]), np.array(data_2[3])\n",
    "\n",
    "# rand_idx = random.sample(range(X_train_2.shape[0]), X_train_1.shape[0]) # double the training data by adding noncovalent data\n",
    "# X_train, y_train = np.vstack([X_train_1, X_train_2[rand_idx]]), np.append(y_train_1, y_train_2[rand_idx])\n",
    "# X_valid, y_valid = X_valid_1, y_valid_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined_model_data', 'wb') as filename:\n",
    "    pickle.dump([X_train, y_train, X_valid, y_valid], filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem-dl-fastai-env",
   "language": "python",
   "name": "chem-dl-fastai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
